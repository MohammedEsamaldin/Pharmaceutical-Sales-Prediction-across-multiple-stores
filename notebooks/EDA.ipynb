{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.data_vizualization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d75c16f2f2c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_vizualization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mData_Viz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_cleaning\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataCleaner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_transformation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mDC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataCleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scripts.data_vizualization'"
     ]
    }
   ],
   "source": [
    "from scripts.data_vizualization import Data_Viz \n",
    "from scripts.data_cleaning import DataCleaner\n",
    "from scripts.data_transformation import DataTransformer\n",
    "\n",
    "DC = DataCleaner()\n",
    "DV = Data_Viz()\n",
    "DT = DataTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the datasets\n",
    "\n",
    "train_data = pd.read_csv('../data/train_store.csv')\n",
    "test_data = pd.read_csv('../data/test_store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the total promotion percentage in both the training and test dataset\n",
    "\n",
    "promo_test_percentage = test_data['Promo'].value_counts(0)[1]/(test_data['Promo'].value_counts(0)[1]+test_data['Promo'].value_counts(0)[0])\n",
    "promo_train_percentage = train_data['Promo'].value_counts(0)["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of percentages\n",
    "\n",
    "print(f'There are {promo_test_percentage:.2%} of promotion in the test data set ')\n",
    "print(f'There are {promo_train_percentage:.2%} of promotion in the train data set ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test and train promo data frame for visualization\n",
    "\n",
    "promo_test_df = test_data['Promo'].value_counts()\n",
    "promo_train_df = train_data['Promo'].value_counts()\n",
    "# Creating a data frame for visualization\n",
    "\n",
    "test_df = pd.DataFrame(promo_test_df)\n",
    "train_df = pd.DataFrame(promo_train_df)\n",
    "# Renaming the columns for visualization\n",
    "\n",
    "promo = [0,1]\n",
    "test_df['Promotion'] = promo\n",
    "train_df['Promotion'] = promo\n",
    "test_df.rename(columns={'Promo':'Count'},inplace=True)\n",
    "train_df.rename(columns={'Promo':'Count'},inplace=True)\n",
    "# Plotting the test promo distribution \n",
    "\n",
    "test_df.plot(kind='bar',rot=0)\n",
    "plt.xlabel('Promotion')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Promotion distribution of test dataset')\n",
    "plt.gca().get_legend().remove()\n",
    "plt.savefig('../charts/test_dataset_promo_distribution.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the train promo distribution \n",
    "\n",
    "train_df.plot(kind='bar',rot=0)\n",
    "plt.xlabel('Promotion')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Promotion distribution of train dataset')\n",
    "plt.gca().get_legend().remove()\n",
    "plt.savefig('../charts/train_dataset_promo_distribution.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the state holiday field\n",
    "\n",
    "train_data['StateHoliday'].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing all the fields of the state holiday into string\n",
    "\n",
    "train_data['StateHoliday'] = train_data['StateHoliday'].values.astype(str)\n",
    "train_data['StateHoliday'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the state holiday fields to easy understandable names\n",
    " \n",
    "train_data['StateHoliday'].replace({'0':'No Holiday','a':'Public Holiday','b':'Easter Holiday','c':'Christmas Holiday'},inplace=True)\n",
    "# Ensuring if the train data column values has changed\n",
    "\n",
    "train_data['StateHoliday'].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the date column for further analysis\n",
    "\n",
    "DC.convert_to_datetime(train_data, ['Date'])\n",
    "train_data['Year'] = train_data['Date'].apply(lambda x: x.year)\n",
    "train_data['Month'] = train_data['Date'].apply(lambda x: x.month)\n",
    "train_data['DayOfMonth'] = train_data['Date'].apply(lambda x: x.day)\n",
    "train_data['Weekday'] = train_data['DayOfWeek'].apply(lambda x: 0 if (x in [6, 7]) else 1) # Identifying if the day is weekend or weekday\n",
    "# Create a new analysed train_data\n",
    "\n",
    "train_data.to_csv('../data/train_data_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data and making the index the date to make it easier for the time series analysis\n",
    "\n",
    "train = pd.read_csv('../data/train_data_clean.csv',index_col='Date')\n",
    "test = pd.read_csv('../data/train_data_clean.csv',index_col='Date')\n",
    "# Finding out all the easter holidays\n",
    "\n",
    "easter_holiday_list = train['StateHoliday'].where(train['StateHoliday']=='Easter Holiday')\n",
    "easter_holiday_list = easter_holiday_list.dropna()\n",
    "print(f'These are the easter holidays from 2013-2015:\\n {easter_holiday_list.index.unique().tolist()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out all the public holidays\n",
    "\n",
    "public_holiday_list = train['StateHoliday'].where(train['StateHoliday']=='Public Holiday')\n",
    "public_holiday_list = public_holiday_list.dropna()\n",
    "print(f'These are the public holidays from 2013-2015:\\n {public_holiday_list.index.unique().tolist()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out all the public holidays\n",
    "\n",
    "public_holiday_list = train['StateHoliday'].where(train['StateHoliday']=='Public Holiday')\n",
    "public_holiday_list = public_holiday_list.dropna()\n",
    "print(f'These are the public holidays from 2013-2015:\\n {public_holiday_list.index.unique().tolist()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out all the Christmas holidays\n",
    "\n",
    "christmas_holiday_list = train['StateHoliday'].where(train['StateHoliday']=='Christmas Holiday')\n",
    "christmas_holiday_list = christmas_holiday_list.dropna()\n",
    "print(f'These are the Christmas holidays from 2013-2015:\\n {christmas_holiday_list.index.unique().tolist()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales Comparision on State Holiday\n",
    "\n",
    "train_store_holiday = train.groupby('StateHoliday').agg({'Sales': 'mean'})\n",
    "train_store_holiday['StateHoliday'] = train_store_holiday.index\n",
    "# Plotting the average sales per State holidays\n",
    "\n",
    "train_store_holiday.plot(kind='bar',x='StateHoliday',y='Sales',rot='0',color=['black', 'red', 'green', 'blue'])\n",
    "plt.title('Average sales')\n",
    "plt.xlabel('State Holidays')\n",
    "plt.ylabel('Average Sales')\n",
    "plt.gca().get_legend().remove() # Removing the legend since we are working on univariate analysis\n",
    "plt.savefig('../charts/average_sales_analysis.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a date column from the index \n",
    "\n",
    "train['date'] = train.index\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the before after and during time stamp dataframe for 2014/15\n",
    "\n",
    "before_index = (train[\"date\"] >= pd.to_datetime(\"2014-11-25\")) & (train[\"date\"] < pd.to_datetime(\"2014-12-25\")) # Taking the one month before xmass\n",
    "before_xmass = train[before_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "during_index = (train[\"date\"] >= pd.to_datetime(\"2014-12-25\")) & (train[\"date\"] < pd.to_datetime(\"2014-12-30\")) # Thinking that the holiday will last for 6 days\n",
    "during_xmass = train[during_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "after_index = (train[\"date\"] >= pd.to_datetime(\"2015-01-01\")) & (train[\"date\"] < pd.to_datetime(\"2015-02-02\"))# Taking the one month after xmass\n",
    "after_xmass = train[after_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "# Plotting the graph of xmass sales before, after and during\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(x = before_xmass.index, y = before_xmass[\"Sales\"], label='Before')\n",
    "sns.lineplot(x = during_xmass.index, y = during_xmass[\"Sales\"], label='During')\n",
    "sns.lineplot(x = after_xmass.index, y = after_xmass[\"Sales\"], label='After')\n",
    "\n",
    "plt.title(\"Christmass Sales 2014/2015\", size=20)\n",
    "plt.xticks(rotation=75, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(xlabel=\"Date\", fontsize=16)\n",
    "plt.ylabel(ylabel=\"Avg Sales\", fontsize=16)\n",
    "plt.savefig('../charts/christmass_sales_analysis_14-15.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the before after and during time stamp dataframe for 2013/14\n",
    "\n",
    "before_index = (train[\"date\"] >= pd.to_datetime(\"2013-11-25\")) & (train[\"date\"] < pd.to_datetime(\"2013-12-25\")) # Taking the one month before xmass\n",
    "before_xmass = train[before_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "during_index = (train[\"date\"] >= pd.to_datetime(\"2013-12-25\")) & (train[\"date\"] < pd.to_datetime(\"2013-12-30\")) # Thinking that the holiday will last for 6 days\n",
    "during_xmass = train[during_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "after_index = (train[\"date\"] >= pd.to_datetime(\"2014-01-01\")) & (train[\"date\"] < pd.to_datetime(\"2014-02-02\"))# Taking the one month after xmass\n",
    "after_xmass = train[after_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "# Plotting the graph of xmass sales before, after and during\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(x = before_xmass.index, y = before_xmass[\"Sales\"], label='Before')\n",
    "sns.lineplot(x = during_xmass.index, y = during_xmass[\"Sales\"], label='During')\n",
    "sns.lineplot(x = after_xmass.index, y = after_xmass[\"Sales\"], label='After')\n",
    "\n",
    "plt.title(\"Christmass Sales 2013/2014\", size=20)\n",
    "plt.xticks(rotation=75, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(xlabel=\"Date\", fontsize=16)\n",
    "plt.ylabel(ylabel=\"Avg Sales\", fontsize=16)\n",
    "plt.savefig('../charts/christmass_sales_analysis_13-14.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easter_holiday_list.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the before after and during time stamp dataframe for 2013/14\n",
    "\n",
    "before_index = (train[\"date\"] >= pd.to_datetime(\"2013-02-28\")) & (train[\"date\"] < pd.to_datetime(\"2013-03-29\")) # Taking the one month before easter\n",
    "before_easter = train[before_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "during_index = (train[\"date\"] >= pd.to_datetime(\"2013-03-29\")) & (train[\"date\"] < pd.to_datetime(\"2013-04-01\")) # Thinking that the holiday will last for 3 days\n",
    "during_easter = train[during_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "after_index = (train[\"date\"] >= pd.to_datetime(\"2013-04-02\")) & (train[\"date\"] < pd.to_datetime(\"2013-05-01\"))# Taking the one month after easter\n",
    "after_easter = train[after_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "# Plotting the graph of Easter sales before, after and during\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(x = before_easter.index, y = before_easter[\"Sales\"], label='Before')\n",
    "sns.lineplot(x = during_easter.index, y = during_easter[\"Sales\"], label='During')\n",
    "sns.lineplot(x = after_easter.index, y = after_easter[\"Sales\"], label='After')\n",
    "\n",
    "plt.title(\"Easter Sales 2013/2014\", size=20)\n",
    "plt.xticks(rotation=75, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(xlabel=\"Date\", fontsize=16)\n",
    "plt.ylabel(ylabel=\"Avg Sales\", fontsize=16)\n",
    "plt.savefig('../charts/easter_sales_analysis_13-14.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the before after and during time stamp dataframe for 2014/15\n",
    "\n",
    "before_index = (train[\"date\"] >= pd.to_datetime(\"2015-03-03\")) & (train[\"date\"] < pd.to_datetime(\"2015-04-03\")) # Taking the one month before easter\n",
    "before_easter = train[before_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "during_index = (train[\"date\"] >= pd.to_datetime(\"2015-04-03\")) & (train[\"date\"] < pd.to_datetime(\"2015-04-06\")) # Thinking that the holiday will last for 6 days\n",
    "during_easter = train[during_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "\n",
    "after_index = (train[\"date\"] >= pd.to_datetime(\"2015-04-06\")) & (train[\"date\"] < pd.to_datetime(\"2015-05-06\"))# Taking the one month after easter\n",
    "after_easter = train[after_index].groupby(\"date\").agg({\"Sales\": \"mean\"})\n",
    "# Plotting the graph of Easter sales before, after and during\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(x = before_easter.index, y = before_easter[\"Sales\"], label='Before')\n",
    "sns.lineplot(x = during_easter.index, y = during_easter[\"Sales\"], label='During')\n",
    "sns.lineplot(x = after_easter.index, y = after_easter[\"Sales\"], label='After')\n",
    "\n",
    "plt.title(\"Easter Sales 2014/2015\", size=20)\n",
    "plt.xticks(rotation=75, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(xlabel=\"Date\", fontsize=16)\n",
    "plt.ylabel(ylabel=\"Avg Sales\", fontsize=16)\n",
    "plt.savefig('../charts/easter_sales_analysis_14-15.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pointing out the fields for correlation check\n",
    "\n",
    "fields_to_check_correlation = ['Sales','Customers']\n",
    "sample_check_for_corr = train[fields_to_check_correlation]\n",
    "sample_check_for_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a correlation heatmap\n",
    "\n",
    "corr = sample_check_for_corr.corr()\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(data=corr, annot = True)\n",
    "plt.savefig('../charts/correlation_heatmap.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be19e6e373137816207eebdc8cdbd35145df7e51669651174e4ed00ef05e2df6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
